{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Execute Kubeflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in ./.local/lib/python3.7/site-packages (20.2.4)\n",
      "Requirement already up-to-date: kfp in ./.local/lib/python3.7/site-packages (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: strip-hints in ./.local/lib/python3.7/site-packages (from kfp) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<12.0.0,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (11.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /opt/conda/lib/python3.7/site-packages (from kfp) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.30.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/conda/lib/python3.7/site-packages (from kfp) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: click in /opt/conda/lib/python3.7/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /opt/conda/lib/python3.7/site-packages (from kfp) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in ./.local/lib/python3.7/site-packages (from kfp) (1.2.10)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<2.0.0,>=0.2.5 in ./.local/lib/python3.7/site-packages (from kfp) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.22.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.8.0 in ./.local/lib/python3.7/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints->kfp) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=14.05.14 in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (50.3.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.24.2 in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated->kfp) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp) (20.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.22.4)\n",
      "Requirement already satisfied, skipping upgrade: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage>=1.13.0->kfp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.52.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage>=1.13.0->kfp) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage>=1.13.0->kfp) (2.20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upgrade pip, install kfp, and restart kernel\n",
    "\n",
    "!python -m pip install --user --upgrade pip\n",
    "!pip install --user --upgrade kfp\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Kubeflow SDK\n",
    "import os\n",
    "import sys\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Container Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "\n",
    "***NOTE -*** Intentionally not importing the `sts.data.loader.load_california_electricity_demand` function here to demonstrate using a base image and installing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, api_key):\n",
    "    \n",
    "    # since we are using a base python Docker image for this component, we need to manually install dependencies\n",
    "    # the other option would be to create Docker image specifically for each component in our pipeline (which we'll do later)\n",
    "    \n",
    "    # defining the install function\n",
    "    import os\n",
    "    import json\n",
    "    import subprocess\n",
    "    def install(name):\n",
    "        subprocess.call(['pip', 'install', name])\n",
    "        \n",
    "    # install load_data dependencies\n",
    "    install('pandas==1.1.0')\n",
    "    install('requests==2.22.0')\n",
    "    \n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    \n",
    "    def read_or_download_data(filepath, api_key_env):\n",
    "\n",
    "        if os.path.exists(filepath):\n",
    "            data = read_json(filepath)\n",
    "        else:\n",
    "            api_key = try_get_env(api_key_env)\n",
    "            response_json = fetch_california_demand(api_key)  \n",
    "            write_json(response_json, filepath)\n",
    "            data = read_json(filepath)\n",
    "            \n",
    "            print(f'------- SUCCESSFULLY SAVED DATE TO: {filepath} -------')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def read_json(file):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def write_json(data, filepath):\n",
    "        with open(filepath, 'w') as file:\n",
    "            json.dump(data, file)\n",
    "\n",
    "\n",
    "    def try_get_env(api_key_env):\n",
    "        env = os.getenv(api_key_env)\n",
    "        if env:\n",
    "            return env\n",
    "        else:\n",
    "            print('Please provide a valid EIA_API_KEY environment variable.')\n",
    "            return None\n",
    "\n",
    "\n",
    "    def fetch_california_demand(api_key):\n",
    "        r = requests.get(\n",
    "            'http://api.eia.gov/series',\n",
    "            params={\n",
    "                'api_key': api_key,\n",
    "                'series_id': 'EBA.CAL-ALL.D.H',\n",
    "                'out': 'json'\n",
    "            }\n",
    "        )\n",
    "        return r.json()\n",
    "\n",
    "\n",
    "    def json_to_df(data):\n",
    "        df = pd.DataFrame(data['series'][0]['data'])\n",
    "        return df\n",
    "    \n",
    "    # ---------------- EXECUTION -----------------\n",
    "    \n",
    "    data = read_or_download_data(data_path+'/demand.json', api_key)\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_path):\n",
    "    \n",
    "    # defining the install function\n",
    "    import subprocess\n",
    "    def install(name):\n",
    "        subprocess.call(['pip', 'install', name])\n",
    "        \n",
    "    # install load_data dependencies\n",
    "    install('pandas==1.1.0')\n",
    "    \n",
    "    import json\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    \n",
    "    def json_to_df(data):\n",
    "        df = pd.DataFrame(data['series'][0]['data'])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    # ---------------- EXECUTION -----------------\n",
    "    \n",
    "    with open(data_path+'/demand.json') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    df = (\n",
    "        json_to_df(data)\n",
    "        .rename(columns={0: 'ds', 1: 'y'})\n",
    "        .assign(ds=utc_to_pst)\n",
    "        .assign(ds=lambda df: df.ds.dt.tz_localize(None))\n",
    "        .sort_values('ds')\n",
    "    )\n",
    "    \n",
    "    with open(data_path+'/data_df.pkl', 'wb') as f:\n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_forecast_simple_model(data_path):\n",
    "    \n",
    "    # defining the install function\n",
    "    import subprocess\n",
    "    def install(name):\n",
    "        subprocess.call(['pip', 'install', name])\n",
    "        \n",
    "    # install load_data dependencies\n",
    "    install('pandas==1.1.0')\n",
    "    install('fbprophet==0.6')\n",
    "    \n",
    "    import os\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    from fbprophet import Prophet\n",
    "\n",
    "    def default_prophet_model(df):\n",
    "        model = Prophet()\n",
    "        model.fit(df)\n",
    "        return model\n",
    "    \n",
    "    # ---------------- EXECUTION -----------------\n",
    "    \n",
    "    with open(data_path+'/data_df.pkl', 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    model = default_prophet_model(df)\n",
    "\n",
    "    future = model.make_future_dataframe(periods = 8760, freq='H')\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Write the forecast values to csv\n",
    "    FORCAST_DIR = data_path+'/forecasts'\n",
    "    if not os.path.exists(FORCAST_DIR):\n",
    "        os.makedirs(FORCAST_DIR)\n",
    "\n",
    "    forecast[['ds', 'yhat']].to_csv(FORCAST_DIR + 'prophet_simple.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create load, preprocess, train components\n",
    "load_data_op = comp.func_to_container_op(load_data, base_image='python:3.6.9')\n",
    "preprocess_data_op = comp.func_to_container_op(preprocess_data, base_image='python:3.6.9')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Kubeflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "    name='Structural Time-Series Pipeline',\n",
    "    description='A step-by-step pipeline for forcasting California energy demand.'\n",
    ")\n",
    "\n",
    "# Define pipeline function and input parameters\n",
    "def sts_container_pipeline(\n",
    "    data_path,\n",
    "    api_key\n",
    "):\n",
    "    \n",
    "    # Define and create a volume to share between pipeline components\n",
    "    vop = dsl.VolumeOp(\n",
    "        name='create_volume_arr',\n",
    "        resource_name='sts-data-volume',\n",
    "        size='0.5Gi',\n",
    "        modes=dsl.VOLUME_MODE_RWO\n",
    "        )\n",
    "    \n",
    "    # Add load_data component\n",
    "    load_data_container = load_data_op(data_path, api_key) \\\n",
    "                                .add_pvolumes({data_path: vop.volume})\n",
    "    \n",
    "    # Add preprocess_data component\n",
    "    preprocess_data_container = preprocess_data_op(data_path) \\\n",
    "                                .add_pvolumes({data_path:load_data_container.pvolume})\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt'\n",
    "API_KEY = 'xyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = sts_container_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'sts_loaddata_test'\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH,\n",
    "             \"api_key\":API_KEY}\n",
    "\n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "kfp.compiler.Compiler().compile(pipeline_func,f'{experiment_name}.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(host='2dba4b335ce47b69-dot-us-east1.pipelines.googleusercontent.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://2dba4b335ce47b69-dot-us-east1.pipelines.googleusercontent.com/#/experiments/details/db7c3572-b3ad-4232-a761-9c074731ea45\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://2dba4b335ce47b69-dot-us-east1.pipelines.googleusercontent.com/#/runs/details/e054dd90-8ac9-468b-a605-4e2606e8ade9\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Submit pipeline directly from pipeline function\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  run_name=run_name,\n",
    "                                                  experiment_name=experiment_name,\n",
    "                                                  arguments=arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get('KF_PIPELINES_ENDPOINT_ENV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/structural-time-series-vol-1/structural-time-series'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(os.path.join('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.os.path.join('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/structural-time-series-vol-1/structural-time-series/nbs\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/structural-time-series-vol-1/structural-time-series/nbs'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \n",
    "    # since we are using a base tensorflow/python Docker image, we need to manually install dependencies\n",
    "    # the other option would be to create Docker image specifically for each component in our pipeline\n",
    "    \n",
    "    # defining the install function\n",
    "    import subprocess\n",
    "    def install(name):\n",
    "        subprocess.call(['pip', 'install', name])\n",
    "    \n",
    "    # func_to_container_op requires packages to be imported inside of the function"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
